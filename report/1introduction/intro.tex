\chapter{Introduction}
Global illumination refers to techniques in rendering and computer graphics in which you illuminate from indirect sources, as opposed to direct light sources exclusively. This can refer to the evenly distributed light transfer between diffuse surfaces, also known as radiosity, the propagation of light through a material that lights up the entire object, refraction/reflection of light through a glass object etc. Depending on the material, light will behave differently when it comes into contact with it, creating all sorts of effects. In this thesis I will work with a couple of different global illumination effects in screen-space. Screen-space methods are methods in which you consider only the geometry visible on the screen when you do shading. These types of methods are popular in real-time and interactive applications because they limit the problem domain to the part of a scene visible from the eye, and often run faster than methods that consider the entire scene. Implementing global illumination as screen-space methods may sound like an oxymoron, since the concept of "global" is lost when you limit the part of the scene you're considering to just what the eye can see. This is why I will use what is known as a deep G-buffer. The deep G-buffer is a way to save screen-space geometry in such a way that rather than just having what the eye can see, we also have access to whatever is behind that. If you removed everything your eye can see, the deep G-buffer has access to all the geometry in the new field of vision. The idea is that this will provide some scene consistency, which is important for global illumination. I will use the deep G-buffer to implement radiosity, which is a method by which to calculate light transfer between diffuse surfaces, and ambient occlusion, which is a method to determine how "shaded" a point is from ambient lighting. As part of this I will document and implement an omni-directional shadow map, which is a way to determine whether or not a given point is in shade from a light source, as well as a way to deduct information about the geometry in screen-space using as little data as possible, and a way to filter noisy images to make them more smooth. I will start by explaining the theory behind these concepts and move on to explain the way they're implemented with concrete code samples. Finally I will present my results, discuss them and provide conclusions.